"""
Project AIO: Japanese Quiz Dataset

Project AIO (AI王) is a Japanese quiz format competition that has been held three times as of June 2023. The first competition used the JAQKET dataset, while further competitions have used similar but different data to challenge models. 

Homepage: https://sites.google.com/view/project-aio/home
"""
import numpy as np
import sacrebleu
import datasets
from rouge_score import rouge_scorer, scoring
from lm_eval.base import rf, Task
from lm_eval.metrics import mean



#TODO use bibtex for a site?
_CITATION = """
https://sites.google.com/view/project-aio/home
"""


class Aiou(Task):
    """This is the closed-book version of the task, where no candidate answers are provided.
    """
    VERSION = 1
    # custom prompt
    PROMPT_VERSION = 0.0
    DATASET_PATH = "polm-stability/project-aio"
    DATASET_NAME = None
    DESCRIPTION = "与えた質問に答えてください。\n\n"

    def __init__(self):
        super().__init__()

    def has_training_docs(self):
        return True

    def has_validation_docs(self):
        return True

    def has_test_docs(self):
        return False

    def validation_docs(self):
        return self.dataset["validation"]

    def train_docs(self):
        return self.dataset["train"]

    def doc_to_text(self, doc):
        return doc["question"] + "\n\n"

    def doc_to_target(self, doc):
        target = " || ".join(doc["answers"])
        return target

    def construct_requests(self, doc, ctx):
        """Uses RequestFactory to construct Requests and returns an iterable of
        Requests which will be sent to the LM.

        :param doc:
            The document as returned from training_docs, validation_docs, or test_docs.
        :param ctx: str
            The context string, generated by fewshot_context. This includes the natural
            language description, as well as the few shot examples, and the question
            part of the document for `doc`.
        """
        completion = rf.greedy_until(ctx, ["\n"])
        return completion

    def process_results(self, doc, results):
        """Take a single document and the LM results and evaluates, returning a
        dict where keys are the names of submetrics and values are the values of
        the metric for that one document

        :param doc:
            The document as returned from training_docs, validation_docs, or test_docs.
        :param results:
            The results of the requests created in construct_requests.
        """
        completion = results[0].strip()

        # the answers handle basic 表記ゆれ, and any exact hit is equally good
        acc = 0.0
        if completion in doc["answers"]:
            acc = 1.0

        return {
            "acc": acc,
        }

    def aggregation(self):
        return {
            "acc": mean,
        }

    def higher_is_better(self):
        return {
            "acc": True,
        }
